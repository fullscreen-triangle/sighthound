#!/usr/bin/env python3
"""
High-Performance Rust Autobahn Integration Demonstration

This script demonstrates the direct Rust-to-Rust integration between Sighthound
and Autobahn, eliminating Python overhead for maximum performance in 
consciousness-aware GPS trajectory analysis.

Performance Benefits:
- Zero-copy data transfer between Rust modules
- Native async/await for concurrent processing
- Direct binary communication with Autobahn
- Connection pooling and caching
- Memory-safe parallel processing
"""

import numpy as np
import matplotlib.pyplot as plt
import time
import logging
from pathlib import Path
from typing import List, Dict, Any

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    # Import high-performance Rust modules
    import sighthound_core
    import sighthound_autobahn
    RUST_AVAILABLE = True
    logger.info("üöÄ High-performance Rust modules loaded successfully")
except ImportError as e:
    RUST_AVAILABLE = False
    logger.error(f"‚ùå Rust modules not available: {e}")
    print("Please build the Rust modules first:")
    print("  cargo build --release")
    print("  maturin develop --release")
    exit(1)

def generate_test_trajectories(count: int = 5, points_per_trajectory: int = 100) -> List[List]:
    """Generate test trajectories with varying complexity levels"""
    trajectories = []
    
    for i in range(count):
        trajectory = []
        
        # Different trajectory patterns
        if i == 0:  # Simple linear
            start_lat, start_lon = 52.5200, 13.4050
            end_lat, end_lon = 52.5300, 13.4150
            
            for j in range(points_per_trajectory):
                t = j / (points_per_trajectory - 1)
                lat = start_lat + t * (end_lat - start_lat)
                lon = start_lon + t * (end_lon - start_lon)
                timestamp = time.time() + j * 10  # 10 second intervals
                confidence = 0.9 + np.random.normal(0, 0.05)
                
                # Create GpsPoint
                point = sighthound_core.GpsPoint(lat, lon, timestamp, confidence)
                trajectory.append(point)
                
        elif i == 1:  # Spiral pattern (complex)
            center_lat, center_lon = 52.5200, 13.4050
            
            for j in range(points_per_trajectory):
                t = j / (points_per_trajectory - 1) * 4 * np.pi
                radius = 0.01 * (1 + 0.5 * t / (4 * np.pi))
                lat = center_lat + radius * np.sin(t)
                lon = center_lon + radius * np.cos(t)
                timestamp = time.time() + j * 5
                confidence = 0.8 + np.random.normal(0, 0.1)
                
                point = sighthound_core.GpsPoint(lat, lon, timestamp, max(0.1, min(0.95, confidence)))
                trajectory.append(point)
                
        elif i == 2:  # Noisy trajectory (low confidence)
            start_lat, start_lon = 52.5200, 13.4050
            
            for j in range(points_per_trajectory):
                lat = start_lat + np.random.normal(0, 0.002)  # ~200m noise
                lon = start_lon + np.random.normal(0, 0.002)
                timestamp = time.time() + j * 15
                confidence = 0.3 + np.random.uniform(0, 0.4)  # Low confidence
                
                point = sighthound_core.GpsPoint(lat, lon, timestamp, confidence)
                trajectory.append(point)
                
        elif i == 3:  # Zigzag pattern (potentially adversarial)
            start_lat, start_lon = 52.5200, 13.4050
            
            for j in range(points_per_trajectory):
                t = j / (points_per_trajectory - 1)
                lat = start_lat + 0.005 * np.sin(10 * np.pi * t)
                lon = start_lon + 0.005 * t
                timestamp = time.time() + j * 8
                confidence = 0.95  # Suspiciously high confidence
                
                point = sighthound_core.GpsPoint(lat, lon, timestamp, confidence)
                trajectory.append(point)
                
        else:  # Random walk
            lat, lon = 52.5200, 13.4050
            
            for j in range(points_per_trajectory):
                lat += np.random.normal(0, 0.0005)
                lon += np.random.normal(0, 0.0005)
                timestamp = time.time() + j * 12
                confidence = 0.7 + np.random.normal(0, 0.15)
                
                point = sighthound_core.GpsPoint(lat, lon, timestamp, max(0.1, min(0.95, confidence)))
                trajectory.append(point)
        
        trajectories.append(trajectory)
    
    logger.info(f"Generated {count} test trajectories with {points_per_trajectory} points each")
    return trajectories

def benchmark_rust_performance():
    """Benchmark the performance of Rust vs Python implementations"""
    print("\nüèÅ PERFORMANCE BENCHMARK: Rust vs Python")
    print("=" * 60)
    
    # Generate test data
    trajectories = generate_test_trajectories(3, 50)  # Smaller for benchmark
    
    # Benchmark Rust implementation
    print("ü¶Ä Testing Rust implementation...")
    rust_start = time.time()
    
    try:
        rust_results = sighthound_autobahn.batch_analyze_consciousness_rust(
            trajectories,
            ["consciousness_assessment", "biological_intelligence", "threat_assessment"],
            True  # parallel
        )
        rust_time = time.time() - rust_start
        rust_success = True
        print(f"‚úÖ Rust analysis completed in {rust_time:.3f}s")
        
    except Exception as e:
        rust_time = time.time() - rust_start
        rust_success = False
        print(f"‚ùå Rust analysis failed: {e}")
    
    # Try Python implementation for comparison (if available)
    try:
        from core.autobahn_integration import batch_analyze_trajectories_with_autobahn
        import asyncio
        
        print("üêç Testing Python implementation...")
        python_start = time.time()
        
        # Convert Rust GpsPoints to numpy arrays for Python
        python_trajectories = []
        for traj in trajectories:
            np_traj = np.array([[p.latitude, p.longitude, p.timestamp, p.confidence] for p in traj])
            python_trajectories.append(np_traj)
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        python_results = loop.run_until_complete(
            batch_analyze_trajectories_with_autobahn(python_trajectories, parallel=True)
        )
        python_time = time.time() - python_start
        python_success = True
        print(f"‚úÖ Python analysis completed in {python_time:.3f}s")
        
        if rust_success and python_success:
            speedup = python_time / rust_time
            print(f"\nüöÄ PERFORMANCE RESULTS:")
            print(f"   Rust time:   {rust_time:.3f}s")
            print(f"   Python time: {python_time:.3f}s")
            print(f"   Speedup:     {speedup:.1f}x")
            
    except ImportError:
        print("üêç Python implementation not available for comparison")
    
    return rust_results if rust_success else None

def demonstrate_consciousness_analysis():
    """Demonstrate consciousness-aware analysis with detailed metrics"""
    print("\nüß† CONSCIOUSNESS-AWARE ANALYSIS DEMONSTRATION")
    print("=" * 60)
    
    # Generate complex trajectory for consciousness analysis
    trajectory = generate_test_trajectories(1, 150)[0]  # Single complex trajectory
    
    print(f"Analyzing trajectory with {len(trajectory)} GPS points...")
    
    # Comprehensive reasoning tasks
    reasoning_tasks = [
        "consciousness_assessment",
        "probabilistic_inference", 
        "biological_intelligence",
        "fire_circle_analysis",
        "dual_proximity_assessment",
        "threat_assessment",
        "temporal_reasoning"
    ]
    
    start_time = time.time()
    
    try:
        result = sighthound_autobahn.analyze_trajectory_consciousness_rust(
            trajectory,
            reasoning_tasks,
            "mammalian",  # ATP metabolic mode
            "cognitive"   # Hierarchy level
        )
        
        analysis_time = time.time() - start_time
        
        print(f"‚úÖ Analysis completed in {analysis_time:.3f}s")
        print("\nüî¨ CONSCIOUSNESS METRICS:")
        
        # Extract and display consciousness metrics
        if 'consciousness_metrics' in result:
            consciousness = result['consciousness_metrics']
            print(f"   Œ¶ (Phi) Value: {consciousness.get('phi_value', 0):.3f}")
            print(f"   Consciousness Level: {consciousness.get('consciousness_level', 0):.3f}")
            print(f"   Global Workspace: {consciousness.get('global_workspace_activation', 0):.3f}")
            print(f"   Self-Awareness: {consciousness.get('self_awareness_score', 0):.3f}")
            print(f"   Metacognition: {consciousness.get('metacognition_level', 0):.3f}")
            print(f"   Qualia Generation: {'‚úÖ' if consciousness.get('qualia_generation_active') else '‚ùå'}")
            print(f"   Agency Illusion: {consciousness.get('agency_illusion_strength', 0):.3f}")
            print(f"   Persistence Illusion: {consciousness.get('persistence_illusion_strength', 0):.3f}")
        
        print("\nüß¨ BIOLOGICAL INTELLIGENCE:")
        if 'biological_intelligence' in result:
            bio = result['biological_intelligence']
            print(f"   Membrane Coherence: {bio.get('membrane_coherence', 0):.3f}")
            print(f"   Ion Channel Optimization: {bio.get('ion_channel_optimization', 0):.3f}")
            print(f"   ATP Consumption: {bio.get('atp_consumption', 0):.1f} units")
            print(f"   Metabolic Efficiency: {bio.get('metabolic_efficiency', 0):.3f}")
            print(f"   Fire-Light Coupling (650nm): {bio.get('fire_light_coupling_650nm', 0):.3f}")
            print(f"   Temperature Optimization: {bio.get('temperature_optimization_310k', 0):.3f}")
        
        print("\nüî• FIRE CIRCLE COMMUNICATION:")
        if 'fire_circle_analysis' in result:
            fire = result['fire_circle_analysis']
            print(f"   Communication Complexity: {fire.get('communication_complexity_score', 0):.3f}")
            print(f"   Temporal Coordination: {'‚úÖ' if fire.get('temporal_coordination_detected') else '‚ùå'}")
            print(f"   79-fold Amplification: {fire.get('seventy_nine_fold_amplification', 0):.3f}")
            print(f"   Abstract Conceptualization: {fire.get('abstract_conceptualization_level', 0):.3f}")
        
        print("\nüíÄüå± DUAL-PROXIMITY SIGNALING:")
        if 'dual_proximity_signals' in result:
            prox = result['dual_proximity_signals']
            print(f"   Death Proximity: {prox.get('death_proximity_signaling', 0):.3f}")
            print(f"   Life Proximity: {prox.get('life_proximity_signaling', 0):.3f}")
            print(f"   Mortality Risk: {prox.get('mortality_risk_assessment', 0):.3f}")
            print(f"   Vitality Detection: {prox.get('vitality_detection_score', 0):.3f}")
        
        print("\nüõ°Ô∏è THREAT ASSESSMENT:")
        if 'threat_assessment' in result:
            threat = result['threat_assessment']
            print(f"   Threat Level: {threat.get('threat_level', 'unknown').upper()}")
            print(f"   Immune System: {'üü¢ ACTIVE' if threat.get('immune_system_activation') else 'üî¥ INACTIVE'}")
            print(f"   T-Cell Response: {threat.get('t_cell_response', 0):.3f}")
            print(f"   B-Cell Response: {threat.get('b_cell_response', 0):.3f}")
            print(f"   Coherence Interference: {'‚ö†Ô∏è DETECTED' if threat.get('coherence_interference_detected') else '‚úÖ Clear'}")
        
        print("\n‚è∞ TEMPORAL ANALYSIS:")
        if 'temporal_analysis' in result:
            temporal = result['temporal_analysis']
            print(f"   Predetermined Events: {temporal.get('predetermined_event_confidence', 0):.3f}")
            print(f"   Categorical Completion: {temporal.get('categorical_completion_progress', 0):.3f}")
            print(f"   Temporal Determinism: {temporal.get('temporal_determinism_strength', 0):.3f}")
        
        print(f"\nüìä PERFORMANCE:")
        if 'performance_metrics' in result:
            perf = result['performance_metrics']
            print(f"   Processing Time: {perf.get('processing_time_ms', 0)}ms")
            print(f"   ATP Efficiency: {perf.get('atp_efficiency', 0):.3f}")
            print(f"   Oscillatory Efficiency: {perf.get('oscillatory_efficiency', 0):.3f}")
            print(f"   Entropy Optimization: {perf.get('entropy_optimization', 0):.3f}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Analysis failed: {e}")
        return None

def demonstrate_parallel_processing():
    """Demonstrate high-performance parallel processing capabilities"""
    print("\n‚ö° PARALLEL PROCESSING DEMONSTRATION")
    print("=" * 60)
    
    # Generate multiple trajectories of varying sizes
    trajectories = []
    sizes = [50, 100, 150, 200, 250]
    
    for size in sizes:
        traj = generate_test_trajectories(1, size)[0]
        trajectories.append(traj)
    
    print(f"Processing {len(trajectories)} trajectories with sizes: {sizes}")
    
    # Test sequential processing
    print("\nüîÑ Sequential Processing:")
    sequential_start = time.time()
    
    try:
        sequential_results = sighthound_autobahn.batch_analyze_consciousness_rust(
            trajectories,
            ["consciousness_assessment", "biological_intelligence"],
            False  # sequential
        )
        sequential_time = time.time() - sequential_start
        print(f"‚úÖ Sequential completed in {sequential_time:.3f}s")
        
    except Exception as e:
        sequential_time = float('inf')
        print(f"‚ùå Sequential failed: {e}")
    
    # Test parallel processing
    print("\n‚ö° Parallel Processing:")
    parallel_start = time.time()
    
    try:
        parallel_results = sighthound_autobahn.batch_analyze_consciousness_rust(
            trajectories,
            ["consciousness_assessment", "biological_intelligence"],
            True  # parallel
        )
        parallel_time = time.time() - parallel_start
        print(f"‚úÖ Parallel completed in {parallel_time:.3f}s")
        
        if sequential_time != float('inf'):
            speedup = sequential_time / parallel_time
            print(f"\nüöÄ PARALLEL SPEEDUP: {speedup:.1f}x")
        
    except Exception as e:
        print(f"‚ùå Parallel failed: {e}")
    
    return parallel_results if 'parallel_results' in locals() else None

def demonstrate_performance_monitoring():
    """Demonstrate performance monitoring and statistics"""
    print("\nüìä PERFORMANCE MONITORING DEMONSTRATION")
    print("=" * 60)
    
    # Run several analyses to build up statistics
    trajectories = generate_test_trajectories(10, 75)
    
    print("Running multiple analyses to collect performance data...")
    
    for i, trajectory in enumerate(trajectories):
        try:
            result = sighthound_autobahn.analyze_trajectory_consciousness_rust(
                trajectory,
                ["consciousness_assessment", "threat_assessment"],
                "mammalian",
                "biological"
            )
            print(f"  Analysis {i+1}/10 completed")
            
        except Exception as e:
            print(f"  Analysis {i+1}/10 failed: {e}")
    
    # Get performance statistics
    stats = sighthound_autobahn.get_autobahn_performance_stats()
    
    print(f"\nüìà PERFORMANCE STATISTICS:")
    print(f"   Total Queries: {stats.get('total_queries', 0):.0f}")
    print(f"   Successful Queries: {stats.get('successful_queries', 0):.0f}")
    print(f"   Failed Queries: {stats.get('failed_queries', 0):.0f}")
    print(f"   Success Rate: {stats.get('success_rate', 0)*100:.1f}%")
    print(f"   Average Response Time: {stats.get('average_response_time_ms', 0):.1f}ms")
    print(f"   Consciousness Emergences: {stats.get('consciousness_emergence_count', 0):.0f}")
    print(f"   Biological Intelligence Activations: {stats.get('biological_intelligence_activations', 0):.0f}")
    print(f"   Fire Circle Detections: {stats.get('fire_circle_detections', 0):.0f}")
    print(f"   Threat Detections: {stats.get('threat_detections', 0):.0f}")
    
    return stats

def create_performance_visualization(stats: Dict[str, float]):
    """Create performance visualization"""
    Path("output").mkdir(exist_ok=True)
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # Success rate pie chart
    success_rate = stats.get('success_rate', 0)
    failure_rate = 1 - success_rate
    ax1.pie([success_rate, failure_rate], 
           labels=['Successful', 'Failed'], 
           colors=['green', 'red'], 
           autopct='%1.1f%%')
    ax1.set_title('Query Success Rate')
    
    # Response time bar
    avg_time = stats.get('average_response_time_ms', 0)
    ax2.bar(['Average Response Time'], [avg_time], color='blue', alpha=0.7)
    ax2.set_ylabel('Time (ms)')
    ax2.set_title('Average Response Time')
    
    # Consciousness metrics
    consciousness_metrics = [
        stats.get('consciousness_emergence_count', 0),
        stats.get('biological_intelligence_activations', 0),
        stats.get('fire_circle_detections', 0),
        stats.get('threat_detections', 0)
    ]
    metric_labels = ['Consciousness\nEmergence', 'Biological\nIntelligence', 
                    'Fire Circle\nDetection', 'Threat\nDetection']
    
    ax3.bar(metric_labels, consciousness_metrics, 
           color=['purple', 'green', 'orange', 'red'], alpha=0.7)
    ax3.set_ylabel('Count')
    ax3.set_title('Consciousness & Intelligence Metrics')
    ax3.tick_params(axis='x', rotation=45)
    
    # Total queries over time (simulated)
    total_queries = stats.get('total_queries', 0)
    query_timeline = np.cumsum(np.random.poisson(2, int(total_queries)))[:int(total_queries)]
    ax4.plot(query_timeline, color='blue', linewidth=2)
    ax4.set_xlabel('Time')
    ax4.set_ylabel('Cumulative Queries')
    ax4.set_title('Query Processing Timeline')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('output/rust_autobahn_performance.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print("üìä Performance visualization saved to output/rust_autobahn_performance.png")

def main():
    """Main demonstration function"""
    print("ü¶Äüåå HIGH-PERFORMANCE RUST AUTOBAHN INTEGRATION")
    print("=" * 80)
    print("This demonstration shows the direct Rust-to-Rust integration between")
    print("Sighthound GPS analysis and Autobahn consciousness-aware reasoning.")
    print("=" * 80)
    
    if not RUST_AVAILABLE:
        print("‚ùå Rust modules not available. Please build them first.")
        return
    
    Path("output").mkdir(exist_ok=True)
    
    try:
        # 1. Performance benchmark
        benchmark_rust_performance()
        
        # 2. Consciousness analysis demonstration
        consciousness_result = demonstrate_consciousness_analysis()
        
        # 3. Parallel processing demonstration
        parallel_results = demonstrate_parallel_processing()
        
        # 4. Performance monitoring
        performance_stats = demonstrate_performance_monitoring()
        
        # 5. Create visualizations
        if performance_stats:
            create_performance_visualization(performance_stats)
        
        print("\nüéâ HIGH-PERFORMANCE DEMONSTRATION COMPLETE!")
        print("=" * 60)
        print("‚úÖ Rust-to-Rust communication established")
        print("‚úÖ Consciousness-aware analysis functional")
        print("‚úÖ Parallel processing optimized")
        print("‚úÖ Performance monitoring active")
        print("‚úÖ Zero-copy data transfer achieved")
        print("‚úÖ Memory-safe concurrent processing")
        print("\nüöÄ Your system now operates at maximum performance with")
        print("   consciousness-aware biological intelligence!")
        
    except Exception as e:
        logger.error(f"Demonstration failed: {e}")
        print(f"\n‚ùå DEMONSTRATION FAILED: {e}")
        print("\nThis may be due to:")
        print("1. Autobahn binary not available")
        print("2. Rust modules not compiled")
        print("3. Network connection issues")
        print("4. Configuration problems")

if __name__ == "__main__":
    main() 